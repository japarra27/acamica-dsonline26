{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS_Bitácora_44_Scraping.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/japarra27/acamica-dsonline26/blob/main/DS_Bit%C3%A1cora_44_Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yte3p-AvsI0u"
      },
      "source": [
        "# Web Scraping\n",
        "\n",
        "En este Notebook pondremos en práctica los contenidos incorporados en la Bitácora. Usaremos la librería Selenium y BeautifulSoup para hacer un breve análisis del portal BBC en Español.\n",
        "\n",
        "Como siempre, hay dos opciones para ejecutar este notebook. Uno es hacerlo en Colab; la otra, en tu computadora. Si utilizas Colab, no debes hacer nada más que correr las celdas correspondientes. Si lo vas a correr en tu computadora, \n",
        "\n",
        ">1. En primer lugar, debes instalar Selenium. Te dejamos la documentación necesaria [aquí](https://selenium-python.readthedocs.io/installation.html).\n",
        ">2. Instala BeautifulSoup (beautifulsoup4).\n",
        "\n",
        "**Para ejecutar en Colab**\n",
        "\n",
        "Este bloque de código instala Selenium y permite ejecutar la librería en Google Colab. Lo encontramos en [esta consulta](https://stackoverflow.com/questions/51046454/how-can-we-use-selenium-webdriver-in-colab-research-google-com) de Stack Overflow. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BjPnvG8RMrf"
      },
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "from selenium import webdriver\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpW8eiNHsI0x"
      },
      "source": [
        "**Para ejecutar en, por ejemplo, Firefox en tu computadora**\n",
        "\n",
        "Ten en cuenta que si usas otro navegador debes modificar las celdas de manera apropiada.\n",
        "\n",
        "Corre las siguientes celdas así como están. Verás que te abre una ventana de tu navegador.\n",
        "\n",
        "Si esa ventana te molesta, descomenta las intrucciones que hay en la primera celda."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZFeAV9QsI0y"
      },
      "source": [
        "from selenium import webdriver\n",
        "\n",
        "# Para que abra navegador\n",
        "wd = webdriver.Firefox()\n",
        "\n",
        "\n",
        "# Para que NO abra navegador\n",
        "# firefox_options = webdriver.FirefoxOptions()\n",
        "# firefox_options.add_argument('--headless')\n",
        "# wd = webdriver.Firefox(options = firefox_options)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNxrc6iW1LJa"
      },
      "source": [
        "Testeamos si Selenium y el Webdriver están funcionando correctamente. Traemos el html del home."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djXqQQqP1YvQ"
      },
      "source": [
        "# Le decimos al Webdriver (wd) que entre a la BBC\n",
        "wd.get('https://www.bbc.com/mundo/')\n",
        "\n",
        "# Con el método page_source guardamos el html en una variable que lleva ese nombre\n",
        "html=wd.page_source\n",
        "\n",
        "# Imprimimos en pantalla\n",
        "html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CIHkMy2QGxv"
      },
      "source": [
        "Al parecer está funcionando bien, pero lo que obtuvimos parece difícil de abordar. \n",
        "\n",
        "Vamos elegir una sección y explorar sus autores. Para eso usaremos la librería BeautifulSoup.\n",
        "\n",
        "Antes de escribir el código:\n",
        "1. Entramos a la sección que queremos analizar y guardamos el link.\n",
        "2. Inspeccionamos el código con el click derecho en el texto que se nombra al autor. **Recomendación**: una vez que abriste el código, si das click derecho sobre la sección del código que te interesa y eliges \"edit as HTML\" podrás copiar la clase, tag o texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU07Y8hBx4qC"
      },
      "source": [
        "#descargamos la librería BeautifulSoup\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#guardamos el link de la seccion en una variable\n",
        "seccionTech =  \"https://www.bbc.com/mundo/topics/cyx5krnw38vt\"\n",
        "\n",
        "#traemos el link de la sección Economía\n",
        "wd.get(seccionTech)\n",
        "\n",
        "#creamos un objeto Soup y lo imprimimos en pantalla\n",
        "html = BeautifulSoup(wd.page_source)\n",
        "html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFssTvM2N7bh"
      },
      "source": [
        "Si bien sigue siendo difícil de abordar, ya tiene otra forma.\n",
        "\n",
        "Localizamos los autores a través del tag y la clase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6Qpw_tzToZU"
      },
      "source": [
        "#cuando inspeccionés la págian, vi que los nombres de los autores están en el tag \"p\" de la siguiente clase\n",
        "authors = html.find_all('p', class_ = \"qa-contributor-name lx-stream-post__contributor-name gel-long-primer gs-u-m0\")\n",
        "authors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t6kC3jzUJMv"
      },
      "source": [
        "# imprimimos sólo el texto\n",
        "for strong_tag in authors:\n",
        "      print(strong_tag.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVubMY4EU2oj"
      },
      "source": [
        "¡Genial! Al parecer funciona bien. Ahora, intentemos utilizar algunas de las ventajas que nos brinda Selenium, para obtener los autores de las otras páginas. Para esto, vamos a utilizar un `for` loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm-FssLVHIe-"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Este array determina cuantas páginas queremos scrapear\n",
        "arrayDePaginas = np.arange(1, 10)\n",
        "# Lista donde guardamos el nombre de los autores\n",
        "listaDeAutores = []\n",
        "\n",
        "# Con este for extraemos el nombre de los autores de cada página y los guardamos en una variable\n",
        "for x in arrayDePaginas:\n",
        "    wd.get(\"https://www.bbc.com/mundo/topics/c7zp57yyz25t/page/\" + str(x))\n",
        "    page = BeautifulSoup(wd.page_source)\n",
        "    for strong_tag in page.find_all('p', class_ = \"qa-contributor-name lx-stream-post__contributor-name gel-long-primer gs-u-m0\"):\n",
        "        # Antes de guardar la información en una lista, podés hacer un print para ver si está funcionando bien\n",
        "        #print(strong_tag.text)\n",
        "        listaDeAutores.append(strong_tag.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2IjQwADWi2M"
      },
      "source": [
        "listaDeAutores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPzylOFtW6cg"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convertimos lista to numpy array\n",
        "arrayDeAutores = np.asarray(listaDeAutores)\n",
        "arrayDeAutores = arrayDeAutores.reshape(-1, 1) \n",
        "\n",
        "# Creamos un dataframe\n",
        "dfDeAutores = pd.DataFrame.from_records(arrayDeAutores, columns=['autores'])\n",
        "dfDeAutores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdKrr937Zaru"
      },
      "source": [
        "#vemos la cantidad de autores\n",
        "dfDeAutores.autores.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay3JvDXAZ1bI"
      },
      "source": [
        "#vemos cuantas notas tiene cada autor\n",
        "dfDeAutores.autores.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iakrtTCWTDVx"
      },
      "source": [
        "#cerramos el browser. Si lo cerras, no vas a poder seguir explorando la web o vas a tener que ejecutar todo desde el principio.\n",
        "wd.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlQVBX1nPaSA"
      },
      "source": [
        "Esto es todo lo que vamos a hacer vinculado al scraping en este Notebook. Te invitamos a que juegues y pruebes distintas secciones del diario, cantidad de páginas scrapeadas y si te animás, otros portales.\n",
        "\n",
        "A continuación, vamos a realizar un breve análisis de la información que recabamos. En este caso vamos a evaluar el género de los autores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft3BBrA6PPkK"
      },
      "source": [
        "# Analizando los datos obtenidos (opcional)\n",
        "\n",
        "Como mencionamos recién, nuestro análisis será breve: queremos determinar el género de los autores. Para eso vamos a utilizar la librería gender-guesser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X25AMN2sf0QW"
      },
      "source": [
        "# Para instalar la librería\n",
        "# !pip install gender-guesser\n",
        "\n",
        "import gender_guesser.detector as gender\n",
        "\n",
        "# Creamos el objeto detector\n",
        "d = gender.Detector()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFoLrpyUk2Bs"
      },
      "source": [
        "#guardamos en una variable los primeros nombres\n",
        "primerNombres = []\n",
        "for i in listaDeAutores:\n",
        "    nombre = i.split(' ', 1)[0]\n",
        "    primerNombres.append(nombre)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FDtzM8gha3m"
      },
      "source": [
        "female = 0\n",
        "male = 0\n",
        "mostly_male = 0\n",
        "mostly_female = 0\n",
        "unknown = 0\n",
        "\n",
        "for x in primerNombres: \n",
        "    genero = d.get_gender(x)\n",
        "    if genero == \"female\":\n",
        "        female += 1\n",
        "    if genero == \"male\":\n",
        "        male += 1\n",
        "    if genero == \"mostly_male\":\n",
        "        mostly_male +=1\n",
        "    if genero == \"mostly_female\":\n",
        "        mostly_female +=1\n",
        "    if genero == \"unknown\":\n",
        "        unknown += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wUsulq3j_Gk"
      },
      "source": [
        "#imprimimos en pantalla\n",
        "print(female)\n",
        "print(male)\n",
        "print(mostly_male)\n",
        "print(mostly_female)\n",
        "print(unknown)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioE37fmOUE5S"
      },
      "source": [
        "Eso es todo por ahora. Hemos visto las bases de dos librerías muy útiles:\n",
        "\n",
        "*   **Selenium WebDriver**: para navegar en la web.\n",
        "*   **BeautifulSoup**: para trabajar el html que obtenemos con Selenium.\n",
        "\n",
        "¡Además aprendiste sobre html! Un conocimiento base que siempre está bueno tener en tecnología."
      ]
    }
  ]
}